import streamlit as st
import requests
from bs4 import BeautifulSoup
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import time
import threading

# --- [1. ê¸°ë³¸ ì„¤ì •] ---
TOKEN = "ì‚¬ìš©ìë‹˜ì˜_í† í°"
CHAT_ID = "8555008565"
STOCKS = ["í•œë¯¸ë°˜ë„ì²´", "HPSP", "ì•Œí…Œì˜¤ì  ", "ABLë°”ì´ì˜¤", "JPHC"]
KEYWORDS = ["ê³µì‹œ", "ì£¼ì£¼", "ì„ìƒ", "ìˆ˜ì£¼", "ê³„ì•½", "ë³´ê³ ì„œ", "JPëª¨ê±´", "ë¸”ë¡ë”œ", "ìœ ë³´", "ë§¤ê°", "ìƒì¥", "ëª©í‘œ"]

# --- [2. ê°•ë ¥í•´ì§„ ë‰´ìŠ¤ íƒìƒ‰ ì—”ì§„] ---
def fetch_verified_news():
    init_db()
    conn = sqlite3.connect('cloud_stock_db.db', check_same_thread=False)
    c = conn.cursor()
    
    # [ê²€ì¦ í¬ì¸íŠ¸] ë„¤ì´ë²„ ì°¨ë‹¨ì„ ëš«ê¸° ìœ„í•œ ì •ë°€ í—¤ë”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://search.naver.com'
    }

    found_logs = []

    for stock in STOCKS:
        # [ê²€ì¦ í¬ì¸íŠ¸] ìµœì‹ ìˆœ ì •ë ¬(&sort=1)ë¡œ í™•ì‹¤í•œ ë°ì´í„° í™•ë³´
        url = f"https://search.naver.com/search.naver?where=news&query={stock}&sm=tab_pge&sort=1&pd=3"
        try:
            res = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # [ê²€ì¦ í¬ì¸íŠ¸] ëª¨ë“  í˜•íƒœì˜ ë‰´ìŠ¤ ë°•ìŠ¤ë¥¼ ë‹¤ ë’¤ì§‘ë‹ˆë‹¤.
            news_items = soup.find_all(['li', 'div'], class_=['bx', 'news_wrap', 'news_area'])
            
            stock_count = 0
            for item in news_items:
                title_tag = item.select_one('a.news_tit')
                if not title_tag: continue
                
                title = title_tag.get_text(strip=True)
                link = title_tag['href']
                date_now = datetime.now().strftime("%Y-%m-%d %H:%M")

                # Push ì•Œë¦¼ ë¡œì§ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
                if any(k in title for k in KEYWORDS):
                    c.execute("SELECT id FROM news WHERE id=?", (link,))
                    if not c.fetchone():
                        msg = f"ğŸš¨ [ì†ë³´ í¬ì°©] {stock}\nì œëª©: {title}\në§í¬: {link}"
                        # í…”ë ˆê·¸ë¨ ì „ì†¡
                        requests.get(f"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={CHAT_ID}&text={msg}")

                try:
                    c.execute("INSERT OR IGNORE INTO news VALUES (?, ?, ?, ?, ?)", (link, stock, date_now, title, link))
                    stock_count += 1
                except: pass
            
            found_logs.append(f"âœ… {stock}: {stock_count}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as e:
            found_logs.append(f"âŒ {stock}: ì—ëŸ¬ ({str(e)})")
            
    conn.commit()
    conn.close()
    return found_logs

def init_db():
    conn = sqlite3.connect('cloud_stock_db.db', check_same_thread=False)
    c.execute('CREATE TABLE IF NOT EXISTS news (id TEXT PRIMARY KEY, stock TEXT, date TEXT, title TEXT, link TEXT)')
    conn.commit()
    conn.close()

# --- [3. ì‚¬ìš©ì ëŒ€ì‹œë³´ë“œ] ---
st.set_page_config(page_title="ì£¼ì‹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ v3.2", layout="wide")
st.title("ğŸ›¡ï¸ ì •ë°€ ê²€ì¦ëœ ì‹¤ì‹œê°„ ì£¼ì‹ ë‰´ìŠ¤ë£¸")

with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì§„ë‹¨")
    if st.button("ğŸ“± í…”ë ˆê·¸ë¨ ì—°ê²° í…ŒìŠ¤íŠ¸"):
        res = requests.get(f"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={CHAT_ID}&text=ğŸ”” ì—°ê²° í™•ì¸ ì™„ë£Œ")
        if res.status_code == 200: st.success("ì•ŒëŒ ì „ì†¡ ì„±ê³µ!")
        else: st.error("ì•ŒëŒ ì‹¤íŒ¨. í† í° í™•ì¸ í•„ìš”.")

# ë©”ì¸ ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸš€ ë°ì´í„° ê°•ì œ ìˆ˜ì§‘ ë° ì—”ì§„ ê°€ë™"):
    with st.spinner('ë„¤ì´ë²„ ë³´ì•ˆ ë§ì„ í†µê³¼í•˜ë©° ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘...'):
        logs = fetch_verified_news()
        for log in logs:
            st.write(log)
    st.rerun()

# ë°ì´í„° í‘œì‹œ ì„¹ì…˜
try:
    conn = sqlite3.connect('cloud_stock_db.db')
    df = pd.read_sql_query("SELECT * FROM news ORDER BY date DESC", conn)
    conn.close()
    
    if not df.empty:
        for stock in STOCKS:
            st.subheader(f"ğŸ“ {stock}")
            s_df = df[df['stock'] == stock]
            if not s_df.empty:
                for _, row in s_df.iterrows():
                    with st.expander(f"[{row['date']}] {row['title']}"):
                        st.write(f"ğŸ”— [ì›ë¬¸ ë³´ê¸°]({row['link']})")
            else: st.caption("ìµœê·¼ 7ì¼ê°„ ì†Œì‹ ì—†ìŒ")
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ [ğŸš€ ê°€ë™] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
except:
    st.info("ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
