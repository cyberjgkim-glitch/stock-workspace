import streamlit as st
import requests
from bs4 import BeautifulSoup
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import time
import threading

# --- [1. ê¸°ë³¸ ì„¤ì •] ---
TOKEN = "ì‚¬ìš©ìë‹˜ì˜_í† í°"
CHAT_ID = "8555008565"
STOCKS = ["í•œë¯¸ë°˜ë„ì²´", "HPSP", "ì•Œí…Œì˜¤ì  ", "ABLë°”ì´ì˜¤", "JPHC"]
KEYWORDS = ["ê³µì‹œ", "ì£¼ì£¼", "ì„ìƒ", "ìˆ˜ì£¼", "ê³„ì•½", "ë³´ê³ ì„œ", "JPëª¨ê±´", "ë¸”ë¡ë”œ", "ìœ ë³´", "ë§¤ê°", "ìƒì¥"]

# --- [2. ì˜¤ë¥˜ ìˆ˜ì •ëœ ì—”ì§„] ---
def init_db():
    conn = sqlite3.connect('cloud_stock_db.db', check_same_thread=False)
    c = conn.cursor() # [ìˆ˜ì •] ì •ì˜ë˜ì§€ ì•Šì•˜ë˜ cë¥¼ ì—¬ê¸°ì„œ ì •ì˜í•©ë‹ˆë‹¤.
    c.execute('CREATE TABLE IF NOT EXISTS news (id TEXT PRIMARY KEY, stock TEXT, date TEXT, title TEXT, link TEXT)')
    conn.commit()
    conn.close()

def fetch_verified_news():
    init_db()
    conn = sqlite3.connect('cloud_stock_db.db', check_same_thread=False)
    c = conn.cursor()
    
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    found_logs = []

    for stock in STOCKS:
        # [ìˆ˜ì •] pd=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê¸°ê°„ ì œí•œ ì—†ì´ ëª¨ë“  í•µì‹¬ ë‰´ìŠ¤ë¥¼ ê¸ì–´ì˜µë‹ˆë‹¤.
        url = f"https://search.naver.com/search.naver?where=news&query={stock}&sort=1&pd=0"
        try:
            res = requests.get(url, headers=headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            news_items = soup.select('ul.list_news li.bx, div.news_wrap, div.news_area')
            
            stock_count = 0
            for item in news_items:
                title_tag = item.select_one('a.news_tit')
                if not title_tag: continue
                title = title_tag.get_text(strip=True)
                link = title_tag['href']
                date_now = datetime.now().strftime("%Y-%m-%d %H:%M")

                if any(k in title for k in KEYWORDS):
                    c.execute("SELECT id FROM news WHERE id=?", (link,))
                    if not c.fetchone():
                        # ì‹¤ì‹œê°„ Push í…ŒìŠ¤íŠ¸ìš©
                        requests.get(f"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={CHAT_ID}&text=ğŸš¨ [ì†ë³´] {stock}\n{title}\n{link}")

                try:
                    c.execute("INSERT OR IGNORE INTO news VALUES (?, ?, ?, ?, ?)", (link, stock, date_now, title, link))
                    stock_count += 1
                except: pass
            found_logs.append(f"âœ… {stock}: {stock_count}ê±´ ìˆ˜ì§‘")
        except: pass
    conn.commit()
    conn.close()
    return found_logs

# --- [3. UI ë° í…ŒìŠ¤íŠ¸ ë²„íŠ¼] ---
st.set_page_config(page_title="ì£¼ì‹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ v3.3", layout="wide")
st.title("ğŸ›¡ï¸ ì •ë°€ ê²€ì¦ ë° Push í…ŒìŠ¤íŠ¸")

with st.sidebar:
    if st.button("ğŸ“± í…”ë ˆê·¸ë¨ Push í…ŒìŠ¤íŠ¸"):
        res = requests.get(f"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={CHAT_ID}&text=ğŸ”” ì‹œìŠ¤í…œ ì—°ê²° í™•ì¸")
        if res.status_code == 200: st.success("í° ì•ŒëŒ ì„±ê³µ!")
        else: st.error("ì•ŒëŒ ì‹¤íŒ¨")

if st.button("ğŸš€ ë°ì´í„° ê°•ì œ ìˆ˜ì§‘ ë° ê²€ì¦"):
    logs = fetch_verified_news()
    for log in logs: st.write(log)
    st.rerun()

# ë°ì´í„° í‘œì‹œ
try:
    conn = sqlite3.connect('cloud_stock_db.db')
    df = pd.read_sql_query("SELECT * FROM news ORDER BY date DESC", conn)
    conn.close()
    if not df.empty:
        for stock in STOCKS:
            st.subheader(f"ğŸ“ {stock}")
            s_df = df[df['stock'] == stock]
            for _, row in s_df.iterrows():
                with st.expander(f"[{row['date']}] {row['title']}"):
                    st.write(f"ğŸ”— [ë§í¬]({row['link']})")
    else: st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
except: st.info("ì¤€ë¹„ ì¤‘...")
